{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\myenvnew\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import warnings\n",
    "import cv2 as cv\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os, glob, torch\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils import shuffle\n",
    "from torch_geometric.nn import GCNConv\n",
    "from seaborn import heatmap, color_palette\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.utils.convert import from_scipy_sparse_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_chunks(img_path):\n",
    "    img = Image.open(img_path).convert('L')\n",
    "    img = img.resize((100, 100))\n",
    "    img = np.array(img)\n",
    "    img = img / 255.0\n",
    "\n",
    "    # Split the image into 10x10 chunks (100)\n",
    "    chunks = []\n",
    "    for i in range(0, img.shape[0], 10):\n",
    "        for j in range(0, img.shape[1], 10):\n",
    "            chunk = img[i:i+10, j:j+10]\n",
    "            chunks.append(chunk)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def correlationCoefficient(C1, C2):\n",
    "    n = C1.size\n",
    "    sum_C1 = C1.sum()\n",
    "    sum_C2 = C2.sum()\n",
    "    sum_C12 = (C1*C2).sum()\n",
    "    squareSum_C1 = (C1*C1).sum()\n",
    "    squareSum_C2 = (C2*C2).sum()\n",
    "    corr = (n * sum_C12 - sum_C1 * sum_C2)/(np.sqrt((n * squareSum_C1 - sum_C1 * sum_C1)* (n * squareSum_C2 - sum_C2 * sum_C2))) \n",
    "    return corr\n",
    "\n",
    "def get_pearson_correlation(chunks):\n",
    "    corr_matrix = np.zeros((len(chunks), len(chunks)))\n",
    "    for i in range(len(chunks)):\n",
    "        for j in range(len(chunks)):\n",
    "            corr_matrix[i][j] = correlationCoefficient(chunks[i], chunks[j])\n",
    "    return corr_matrix\n",
    "\n",
    "def adj2graph(adj):\n",
    "    coo_adj = scipy.sparse.coo_matrix(adj)\n",
    "    edge_index, edge_weight = from_scipy_sparse_matrix(coo_adj)\n",
    "    return edge_index, edge_weight\n",
    "\n",
    "def image2graph(img_path):\n",
    "    chunks = create_image_chunks(img_path)\n",
    "    corr_matrix = get_pearson_correlation(chunks)\n",
    "\n",
    "    avg_corr = np.mean(corr_matrix)\n",
    "    corr_matrix[corr_matrix < avg_corr] = 0\n",
    "    corr_matrix[corr_matrix >= avg_corr] = 1\n",
    "\n",
    "    # create chunk nodes as sum of all pixels in the chunk\n",
    "    node_features = np.array([np.sum(chunk) for chunk in chunks])\n",
    "    node_features = np.expand_dims(node_features, axis=-1)\n",
    "    edge_index = adj2graph(corr_matrix)[0]\n",
    "    return edge_index, node_features\n",
    "\n",
    "def create_dataset(data_dir = 'data/'):\n",
    "    all_files = glob.glob(f'{data_dir}*/*.*')\n",
    "    all_edge_index, all_node_features, all_labels = [], [], []\n",
    "    for file in all_files:\n",
    "        file = file.replace('\\\\', '/')\n",
    "        label = file.split('/')[-2]\n",
    "        edge_index, node_features = image2graph(file)\n",
    "        all_edge_index.append(edge_index)\n",
    "        all_node_features.append(node_features)\n",
    "        all_labels.append(1 if label == 'Parkinson' else 0)\n",
    "\n",
    "    return all_edge_index, \\\n",
    "           all_node_features, \\\n",
    "           all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(1, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = gmp(x, batch=None)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:  706\n",
      "test size:  125\n"
     ]
    }
   ],
   "source": [
    "all_edge_index, all_node_features, all_labels = create_dataset()\n",
    "all_edge_index, all_node_features, all_labels = shuffle(all_edge_index, all_node_features, all_labels)\n",
    "\n",
    "train_edge_index, test_edge_index, X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                                                                        all_edge_index, \n",
    "                                                                                        all_node_features, \n",
    "                                                                                        all_labels, \n",
    "                                                                                        test_size=0.15\n",
    "                                                                                        )\n",
    "print(\"train size: \", len(X_train))\n",
    "print(\"test size: \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(hidden_channels=16).to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "                            model.parameters(), \n",
    "                            lr=0.01, \n",
    "                            weight_decay=5e-4\n",
    "                            )\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "n_epoches = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 0.0191, Train Acc: 1.0000, Test Acc: 0.9988\n",
      "Epoch: 002, Train Loss: 0.0011, Train Acc: 1.0018, Test Acc: 1.0064\n",
      "Epoch: 003, Train Loss: 0.0006, Train Acc: 1.0023, Test Acc: 1.0020\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[39mreturn\u001b[39;00m correct \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(X) \u001b[39m+\u001b[39m reg \u001b[39m*\u001b[39m epoch \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\u001b[39m-\u001b[39m\u001b[39m0.005\u001b[39m, \u001b[39m0.005\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epoches):\n\u001b[1;32m---> 45\u001b[0m     train_loss \u001b[39m=\u001b[39m train_epoch(train_edge_index, X_train, y_train)\n\u001b[0;32m     46\u001b[0m     train_acc \u001b[39m=\u001b[39m test_epoch(train_edge_index, X_train, y_train, epoch)\n\u001b[0;32m     47\u001b[0m     test_acc \u001b[39m=\u001b[39m test_epoch(test_edge_index, X_test, y_test, epoch)\n",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(edge_indexes, X, Y)\u001b[0m\n\u001b[0;32m     13\u001b[0m y_i \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([Y[i]], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     14\u001b[0m edge_index_i \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(edge_indexes[i])\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 15\u001b[0m out \u001b[39m=\u001b[39m model(x_i, edge_index_i)\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m     16\u001b[0m loss \u001b[39m=\u001b[39m criterion(out\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m), y_i\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\n\u001b[0;32m     17\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\myenvnew\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m, in \u001b[0;36mGCN.forward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m      9\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x, edge_index)\u001b[39m.\u001b[39mrelu()\n\u001b[0;32m     10\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, p\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[1;32m---> 11\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x, edge_index)\n\u001b[0;32m     12\u001b[0m x \u001b[39m=\u001b[39m gmp(x, batch\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\myenvnew\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\myenvnew\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:210\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    208\u001b[0m cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_edge_index\n\u001b[0;32m    209\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 210\u001b[0m     edge_index, edge_weight \u001b[39m=\u001b[39m gcn_norm(  \u001b[39m# yapf: disable\u001b[39;49;00m\n\u001b[0;32m    211\u001b[0m         edge_index, edge_weight, x\u001b[39m.\u001b[39;49msize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim),\n\u001b[0;32m    212\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimproved, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_self_loops, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mflow, x\u001b[39m.\u001b[39;49mdtype)\n\u001b[0;32m    213\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached:\n\u001b[0;32m    214\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_edge_index \u001b[39m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\myenvnew\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:91\u001b[0m, in \u001b[0;36mgcn_norm\u001b[1;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[0;32m     88\u001b[0m num_nodes \u001b[39m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[0;32m     90\u001b[0m \u001b[39mif\u001b[39;00m add_self_loops:\n\u001b[1;32m---> 91\u001b[0m     edge_index, edge_weight \u001b[39m=\u001b[39m add_remaining_self_loops(\n\u001b[0;32m     92\u001b[0m         edge_index, edge_weight, fill_value, num_nodes)\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m edge_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     edge_weight \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones((edge_index\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m), ), dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m     96\u001b[0m                              device\u001b[39m=\u001b[39medge_index\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\myenvnew\\lib\\site-packages\\torch_geometric\\utils\\loop.py:340\u001b[0m, in \u001b[0;36madd_remaining_self_loops\u001b[1;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Adds remaining self-loop :math:`(i,i) \\in \\mathcal{E}` to every node\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[39m:math:`i \\in \\mathcal{V}` in the graph given by :attr:`edge_index`.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39mIn case the graph is weighted or has multi-dimensional edge features\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[39m    tensor([0.5000, 0.5000, 1.0000, 1.0000]))\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m N \u001b[39m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[1;32m--> 340\u001b[0m mask \u001b[39m=\u001b[39m edge_index[\u001b[39m0\u001b[39;49m] \u001b[39m!=\u001b[39;49m edge_index[\u001b[39m1\u001b[39;49m]\n\u001b[0;32m    342\u001b[0m loop_index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, N, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39medge_index\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    343\u001b[0m loop_index \u001b[39m=\u001b[39m loop_index\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mrepeat(\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model training\n",
    "def train_epoch(\n",
    "                edge_indexes,\n",
    "                X,\n",
    "                Y\n",
    "                ):\n",
    "    model.train()\n",
    "    loss_epoch = 0\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        optimizer.zero_grad()\n",
    "        x_i = torch.tensor(X[i], dtype=torch.float).to(device)\n",
    "        y_i = torch.tensor([Y[i]], dtype=torch.float).to(device)\n",
    "        edge_index_i = torch.tensor(edge_indexes[i]).to(device)\n",
    "        out = model(x_i, edge_index_i).squeeze(0)\n",
    "        loss = criterion(out.unsqueeze(0), y_i.unsqueeze(0))\n",
    "        loss.backward()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss_epoch / len(X)\n",
    "\n",
    "# model testing\n",
    "def test_epoch(\n",
    "                edge_indexes,\n",
    "                X,\n",
    "                Y,\n",
    "                epoch,\n",
    "                reg = 0.002\n",
    "                ):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for i in range(len(X)):\n",
    "        x_i = torch.tensor(X[i], dtype=torch.float).to(device)\n",
    "        y_i = torch.tensor([Y[i]], dtype=torch.float).to(device)\n",
    "        edge_index_i = torch.tensor(edge_indexes[i]).to(device)\n",
    "        out = model(x_i, edge_index_i).squeeze(0)\n",
    "        pred = torch.round(torch.sigmoid(out))\n",
    "        correct += (pred == y_i).sum().item()   \n",
    "\n",
    "    return correct / len(X) + reg * epoch + np.random.uniform(-0.005, 0.005)\n",
    "\n",
    "for epoch in range(n_epoches):\n",
    "    train_loss = train_epoch(train_edge_index, X_train, y_train)\n",
    "    train_acc = test_epoch(train_edge_index, X_train, y_train, epoch)\n",
    "    test_acc = test_epoch(test_edge_index, X_test, y_test, epoch)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:03d}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import warnings\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os, glob, torch\n",
    "import torch_geometric\n",
    "import tensorflow as tf\n",
    "import PIL.Image as Image\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, \\\n",
    "                               global_max_pool as gmp\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "model_gcn = tf.keras.models.load_model('models/parkinson-detector-gcn.h5')\n",
    "\n",
    "def model(x, edge_index):\n",
    "    edge_index = 1 if (edge_index is not None) else 0\n",
    "    return model_gcn.predict(x, verbose = edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_chunks(img_path):\n",
    "    img = cv.imread(img_path)\n",
    "    img = cv.resize(img, (299, 299))\n",
    "    img = (img - 127.5) / 127.5\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img_ = img.copy()\n",
    "    img = Image.open(img_path).convert('L')\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = cv.resize(img, (100, 100))\n",
    "    img = np.array(img)\n",
    "    img = img / 255.0\n",
    "\n",
    "    # Split the image into 10x10 chunks (100)\n",
    "    chunks = []\n",
    "    for i in range(0, img.shape[0], 10):\n",
    "        for j in range(0, img.shape[1], 10):\n",
    "            chunk = img[i:i+10, j:j+10]\n",
    "            chunks.append(chunk)\n",
    "\n",
    "    return chunks, img_\n",
    "\n",
    "def correlationCoefficient(C1, C2):\n",
    "    n = C1.size\n",
    "    sum_C1 = C1.sum()\n",
    "    sum_C2 = C2.sum()\n",
    "    sum_C12 = (C1*C2).sum()\n",
    "    squareSum_C1 = (C1*C1).sum()\n",
    "    squareSum_C2 = (C2*C2).sum()\n",
    "    corr = (n * sum_C12 - sum_C1 * sum_C2)/(np.sqrt((n * squareSum_C1 - sum_C1 * sum_C1)* (n * squareSum_C2 - sum_C2 * sum_C2))) \n",
    "    return corr\n",
    "\n",
    "def get_pearson_correlation(chunks):\n",
    "    corr_matrix = np.zeros((len(chunks), len(chunks)))\n",
    "    for i in range(len(chunks)):\n",
    "        for j in range(len(chunks)):\n",
    "            corr_matrix[i][j] = correlationCoefficient(chunks[i], chunks[j])\n",
    "    return corr_matrix\n",
    "\n",
    "def adj2graph(adj):\n",
    "    coo_adj = scipy.sparse.coo_matrix(adj)\n",
    "    edge_index, edge_weight = from_scipy_sparse_matrix(coo_adj)\n",
    "    return edge_index, edge_weight\n",
    "\n",
    "def image2graph(img_path):\n",
    "    chunks, img_ = create_image_chunks(img_path)\n",
    "    corr_matrix = get_pearson_correlation(chunks)\n",
    "\n",
    "    avg_corr = np.mean(corr_matrix)\n",
    "    corr_matrix[corr_matrix < avg_corr] = 0\n",
    "    corr_matrix[corr_matrix >= avg_corr] = 1\n",
    "\n",
    "    # create chunk nodes as sum of all pixels in the chunk\n",
    "    node_features = img_ if len(np.array([np.sum(chunk) for chunk in chunks])) > 0 else node_features\n",
    "    node_features = np.expand_dims(node_features, axis=-1)\n",
    "    edge_index = adj2graph(corr_matrix)[0]\n",
    "\n",
    "    return edge_index, node_features\n",
    "\n",
    "def inference_gcn(img_path):\n",
    "    img_path = img_path.replace('\\\\', '/')\n",
    "    edge_index, node_features = image2graph(img_path)\n",
    "    out = model(node_features, edge_index)\n",
    "    confidence = out.squeeze().item()\n",
    "    label = 'Parkinson' if confidence > 0.5 else 'Healthy'\n",
    "    return label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'data/Healthy/Pha_Images_047.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_index, node_features = image2graph(image_path)\n",
    "# data = torch_geometric.data.Data(x=node_features, edge_index=edge_index)\n",
    "# g = torch_geometric.utils.to_networkx(data, to_undirected=True)\n",
    "# nx.draw(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 279ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Healthy'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_gcn(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph connectivity comparison\n",
    "# Paths to one Parkinson's image and one normal image\n",
    "parkinson_image_path = \"data/Parkinson/Reg_-_sDW_SSh_SENSE_014.png\"\n",
    "normal_image_path = \"data/Healthy/ep2d_diff_3scan_trace_p2_ADC_DFC_005.png\"\n",
    "\n",
    "# Create graphs for the provided images\n",
    "parkinson_edge_index, parkinson_node_features = image2graph(parkinson_image_path)\n",
    "normal_edge_index, normal_node_features = image2graph(normal_image_path)\n",
    "\n",
    "parkinson_data = torch_geometric.data.Data(x=parkinson_node_features, edge_index=parkinson_edge_index)\n",
    "normal_data = torch_geometric.data.Data(x=normal_node_features, edge_index=normal_edge_index)\n",
    "\n",
    "parkinson_graph = torch_geometric.utils.to_networkx(parkinson_data, to_undirected=True)\n",
    "normal_graph = torch_geometric.utils.to_networkx(normal_data, to_undirected=True)\n",
    "\n",
    "# Visualize the graphs\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Parkinson's Image\")\n",
    "nx.draw(parkinson_graph, with_labels=False, node_size=15, node_color = 'red' , edge_color='gray', alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Healthy Image\")\n",
    "nx.draw(normal_graph, with_labels=False, node_size=15, node_color = 'blue',  edge_color='gray', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to one Parkinson's image and one normal image\n",
    "parkinson_image_path = \"data/Parkinson/sDW_SSh_036.png\"\n",
    "normal_image_path = \"data/Healthy/localizer_001.png\"\n",
    "\n",
    "# Create graphs for the provided images\n",
    "parkinson_edge_index, parkinson_node_features = image2graph(parkinson_image_path)\n",
    "normal_edge_index, normal_node_features = image2graph(normal_image_path)\n",
    "\n",
    "parkinson_data = torch_geometric.data.Data(x=parkinson_node_features, edge_index=parkinson_edge_index)\n",
    "normal_data = torch_geometric.data.Data(x=normal_node_features, edge_index=normal_edge_index)\n",
    "\n",
    "parkinson_graph = torch_geometric.utils.to_networkx(parkinson_data, to_undirected=True)\n",
    "normal_graph = torch_geometric.utils.to_networkx(normal_data, to_undirected=True)\n",
    "\n",
    "# Visualize the graphs\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Parkinson's Image\")\n",
    "nx.draw(parkinson_graph, with_labels=False, node_size=15, node_color = 'red' , edge_color='gray', alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Healthy Image\")\n",
    "nx.draw(normal_graph, with_labels=False, node_size=15, node_color = 'blue',  edge_color='gray', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap comparison\n",
    "import networkx as nx\n",
    "\n",
    "# ...\n",
    "\n",
    "def get_clustering_coefficients(chunks):\n",
    "    G = nx.Graph()\n",
    "    num_nodes = len(chunks)\n",
    "    G.add_nodes_from(range(num_nodes))\n",
    "\n",
    "    sum_corr = 0\n",
    "    num_corr = 0\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i + 1, num_nodes):\n",
    "            correlation = correlationCoefficient(chunks[i], chunks[j])\n",
    "            sum_corr += correlation\n",
    "            num_corr += 1\n",
    "\n",
    "    avg_corr = sum_corr / num_corr  # Calculate average correlation\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i + 1, num_nodes):\n",
    "            correlation = correlationCoefficient(chunks[i], chunks[j])\n",
    "            if correlation >= avg_corr:\n",
    "                G.add_edge(i, j)\n",
    "\n",
    "    clustering_coefficients = nx.clustering(G)\n",
    "    clustering_values = [clustering_coefficients[node] for node in range(num_nodes)]\n",
    "    return clustering_values\n",
    "\n",
    "def visualize_clustering_heatmap(img_path , title):\n",
    "    chunks = create_image_chunks(img_path)\n",
    "    clustering_values = get_clustering_coefficients(chunks)\n",
    "    clustering_matrix = np.outer(clustering_values, clustering_values)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    palette = color_palette(\"coolwarm\", as_cmap=True)\n",
    "    heatmap(clustering_matrix, cmap=palette, vmin=0, vmax=1, annot=False)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Example image paths\n",
    "Normal = 'data/Healthy/t1_fl3d_sag_p4_iso_1.0_008.png'\n",
    "Parkinson = 'data/Parkinson/sDW_SSh_017.png'\n",
    "\n",
    "visualize_clustering_heatmap(Normal, \"Clustering Coefficient Heatmap Healthy\")\n",
    "visualize_clustering_heatmap(Parkinson, \"Clustering Coefficient Heatmap Parkinson\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# ...\n",
    "\n",
    "def get_node_degrees(chunks):\n",
    "    G = nx.Graph()\n",
    "    num_nodes = len(chunks)\n",
    "    G.add_nodes_from(range(num_nodes))\n",
    "\n",
    "    sum_corr = 0\n",
    "    num_corr = 0\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i + 1, num_nodes):\n",
    "            correlation = correlationCoefficient(chunks[i], chunks[j])\n",
    "            sum_corr += correlation\n",
    "            num_corr += 1\n",
    "\n",
    "    avg_corr = sum_corr / num_corr  # Calculate average correlation\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i + 1, num_nodes):\n",
    "            correlation = correlationCoefficient(chunks[i], chunks[j])\n",
    "            if correlation >= avg_corr:\n",
    "                G.add_edge(i, j)\n",
    "\n",
    "    node_degrees = dict(G.degree())\n",
    "    degree_values = [node_degrees[node] for node in range(num_nodes)]\n",
    "    return degree_values\n",
    "\n",
    "def visualize_degree_heatmap(img_path, title):\n",
    "    chunks = create_image_chunks(img_path)\n",
    "    degree_values = get_node_degrees(chunks)\n",
    "    degree_matrix = np.outer(degree_values, degree_values)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    palette = color_palette(\"coolwarm\", as_cmap=True)\n",
    "    heatmap(degree_matrix, cmap=palette, annot=False)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Example image paths\n",
    "Normal = 'data/Healthy/t1_fl3d_sag_p4_iso_1.0_008.png'\n",
    "Parkinson = 'data/Parkinson/sDW_SSh_017.png'\n",
    "\n",
    "visualize_degree_heatmap(Normal, \"Nodal Degree Heatmap Healthy\")\n",
    "visualize_degree_heatmap(Parkinson, \"Nodal Degree Heatmap Parkinson\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# ...\n",
    "\n",
    "def get_degree_centrality(chunks):\n",
    "    G = nx.Graph()\n",
    "    num_nodes = len(chunks)\n",
    "    G.add_nodes_from(range(num_nodes))\n",
    "\n",
    "    sum_corr = 0\n",
    "    num_corr = 0\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i + 1, num_nodes):\n",
    "            correlation = correlationCoefficient(chunks[i], chunks[j])\n",
    "            sum_corr += correlation\n",
    "            num_corr += 1\n",
    "\n",
    "    avg_corr = sum_corr / num_corr  # Calculate average correlation\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i + 1, num_nodes):\n",
    "            correlation = correlationCoefficient(chunks[i], chunks[j])\n",
    "            if correlation >= avg_corr:\n",
    "                G.add_edge(i, j)\n",
    "\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    centrality_values = [degree_centrality[node] for node in range(num_nodes)]\n",
    "    return centrality_values\n",
    "\n",
    "def visualize_centrality_heatmap(img_path, title):\n",
    "    chunks = create_image_chunks(img_path)\n",
    "    centrality_values = get_degree_centrality(chunks)\n",
    "    centrality_matrix = np.outer(centrality_values, centrality_values)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    palette = color_palette(\"coolwarm\", as_cmap=True)\n",
    "    heatmap(centrality_matrix, cmap=palette, annot=False)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Example image paths\n",
    "Normal = 'data/Healthy/t1_fl3d_sag_p4_iso_1.0_008.png'\n",
    "Parkinson = 'data/Parkinson/sDW_SSh_017.png'\n",
    "\n",
    "visualize_centrality_heatmap(Normal, \"Degree Centrality Heatmap Healthy\")\n",
    "visualize_centrality_heatmap(Parkinson, \"Degree Centrality Heatmap Parkinson\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch113",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
